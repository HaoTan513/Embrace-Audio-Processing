{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcf34a0d-a482-4cee-997e-f548a771dd39",
   "metadata": {},
   "source": [
    "## DeepSeek for Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70462af7-0b1c-4369-8dea-12d427588cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "from dotenv import load_dotenv\n",
    "from pydub import AudioSegment\n",
    "from io import BytesIO\n",
    "import re\n",
    "import time\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "def process_meditation_script_from_file(file_path):\n",
    "    \"\"\"\n",
    "    Process a meditation script from a text file, splitting it by \"\\n\\n\",\n",
    "    and converting each section to SSML format.\n",
    "    \"\"\"\n",
    "    # Read the text from the file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "    \n",
    "    # Split the content into chunks based on double newlines\n",
    "    script_chunks = content.split(\"\\n\\n\")\n",
    "    \n",
    "    # Function to process individual chunks using LLM\n",
    "    def process_chunk(chunk):\n",
    "        api_key = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "        base_url = os.getenv(\"DEEPSEEK_BASE_URL\")\n",
    "\n",
    "        # Initialize the OpenAI client\n",
    "        client = OpenAI(api_key=api_key, base_url=base_url)\n",
    "        prompt = f\"\"\"\n",
    "        Convert the following meditation script into one paragraph and then transform it into SSML format with appropriate breaks: \n",
    "        {chunk}\n",
    "        \"\"\"\n",
    "        system_message = f\"\"\"\n",
    "        You are a meditation expert that converts text to SSML, your response output should be raw SSML start wtih <speak> end with <\\speak>.\n",
    "        The requirements are: \n",
    "        1. There should be 1-second break at every period.\n",
    "        2. There will be 0.5-second break at every comma.\n",
    "        3. When it comes to seconds indicated in square brackets in the text, add break with indicated seconds. For example, there should be 30-second break at [30s] in the text.\n",
    "        \"\"\"\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"deepseek-chat\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_message},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "            stream=False\n",
    "        )\n",
    "        ssml_output = response.choices[0].message.content\n",
    "        return ssml_output\n",
    "    \n",
    "    # Process each chunk and collect SSML outputs\n",
    "    ssml_outputs = [process_chunk(chunk) for chunk in script_chunks if chunk.strip()]\n",
    "    \n",
    "    return ssml_outputs\n",
    "\n",
    "\n",
    "\n",
    "def process_meditation_script_from_file_pure_code(file_path, voice_name=\"en-US-AriaNeural\", prosody_rate=\"-15.00%\"):\n",
    "    \"\"\"\n",
    "    Processes a meditation script from a text file, splits it by \"\\n\\n\",\n",
    "    and converts each section to SSML format with specified prosody and voice settings.\n",
    "\n",
    "    Args:\n",
    "    - file_path (str): Path to the text file containing the meditation script.\n",
    "    - voice_name (str): The name of the Azure Neural voice to use.\n",
    "    - prosody_rate (str): The prosody rate adjustment for the voice.\n",
    "\n",
    "    Returns:\n",
    "    - str: Combined SSML text.\n",
    "    \"\"\"\n",
    "    # Read the text from the file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # Split the content into chunks based on double newlines\n",
    "    script_chunks = content.split(\"\\n\\n\")\n",
    "\n",
    "    # Function to convert a single chunk into SSML\n",
    "    def process_chunk_to_ssml(chunk):\n",
    "        # Replace periods and commas with SSML breaks\n",
    "        # Add a 1-second break after periods\n",
    "        chunk = re.sub(r\"(\\.)\", r'\\1<break time=\"2s\"/>', chunk)\n",
    "        # Add a 0.5-second break after commas\n",
    "        chunk = re.sub(r\"(,)\", r'\\1<break time=\"1s\"/>', chunk)\n",
    "        # Wrap with SSML structure\n",
    "        return f\"\"\"\n",
    "<speak xmlns=\"http://www.w3.org/2001/10/synthesis\" \n",
    "       xmlns:mstts=\"http://www.w3.org/2001/mstts\" \n",
    "       xmlns:emo=\"http://www.w3.org/2009/10/emotionml\" \n",
    "       version=\"1.0\" xml:lang=\"en-US\">\n",
    "  <voice name=\"{voice_name}\">\n",
    "    <s />\n",
    "    <mstts:express-as style=\"whispering\">\n",
    "      <prosody rate=\"{prosody_rate}\">\n",
    "        {chunk}\n",
    "      </prosody>\n",
    "    </mstts:express-as>\n",
    "  </voice>\n",
    "</speak>\n",
    "        \"\"\".strip()\n",
    "\n",
    "    # Process each chunk into SSML\n",
    "    ssml_chunks = [process_chunk_to_ssml(chunk.strip()) for chunk in script_chunks if chunk.strip()]\n",
    "\n",
    "    return ssml_chunks\n",
    "\n",
    "\n",
    "def save_ssml_list_to_file(ssml_list, file_path=\"combined_output.ssml\"):\n",
    "    \"\"\"\n",
    "    Saves a list of SSML texts into one file.\n",
    "\n",
    "    Args:\n",
    "    - ssml_list (list of str): A list of SSML strings to combine and save.\n",
    "    - file_path (str): The path to the file where the combined SSML content will be saved.\n",
    "\n",
    "    Returns:\n",
    "    - str: Confirmation message with the file path.\n",
    "    \"\"\"\n",
    "    # Combine all SSML texts into one string, separated by a newline for readability\n",
    "    combined_ssml = \"\\n\\n\".join(ssml_list)\n",
    "\n",
    "    # Save the combined SSML content to the specified file\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(combined_ssml)\n",
    "\n",
    "    print(f\"All SSML texts have been saved to '{file_path}'.\")\n",
    "    return file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aac784e7-7c67-4660-9d01-52ac057f2a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All SSML texts have been saved to 'combined_output_purecode.ssml'.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "# file_path = \"slices_MVP.txt\"\n",
    "# ssml_outputs = process_meditation_script_from_file(file_path)\n",
    "# ssml_path = save_ssml_list_to_file(ssml_outputs)\n",
    "\n",
    "# Example usage\n",
    "file_path = \"slices_MVP.txt\"\n",
    "ssml_outputs = process_meditation_script_from_file_pure_code(file_path)\n",
    "ssml_path = save_ssml_list_to_file(ssml_outputs, \"combined_output_purecode.ssml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f8ca99",
   "metadata": {},
   "source": [
    "## Genearte AI audio Along with Haptics and Soundscaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13f3559a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from pydub import AudioSegment\n",
    "from io import BytesIO\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "import os\n",
    "from AHAPpy import generate_ahap as ga\n",
    "\n",
    "seed = 17\n",
    "\n",
    "def synthesize_text_to_audio(ssml_text, speech_config):\n",
    "    \"\"\"\n",
    "    Synthesizes SSML text to an audio segment using Azure TTS.\n",
    "    \"\"\"\n",
    "    audio_config = speechsdk.audio.PullAudioOutputStream()\n",
    "    print(\"Attributes of audio_config: \", vars(audio_config))\n",
    "    synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)\n",
    "\n",
    "    # Synthesize the SSML\n",
    "    synthesis_result = synthesizer.speak_ssml_async(ssml_text).get()\n",
    "\n",
    "    if synthesis_result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "        print(\"SynthesizingAudioCompleted\")\n",
    "        audio_data = synthesis_result.audio_data\n",
    "        return AudioSegment.from_file(BytesIO(audio_data), format=\"wav\")\n",
    "    elif synthesis_result.reason == speechsdk.ResultReason.Canceled:\n",
    "        cancellation_details = synthesis_result.cancellation_details\n",
    "        print(f\"Speech synthesis canceled: {cancellation_details.reason}\")\n",
    "        if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "            print(f\"Error details: {cancellation_details.error_details}\")\n",
    "        return None\n",
    "\n",
    "def overlay_background_sound(speech_audio, background_tag, delay = 1000, volume=-15):\n",
    "    \"\"\"\n",
    "    Overlays a background sound onto a speech audio segment.\n",
    "    \"\"\"\n",
    "    background_file = f\"{background_tag}.mp3\"\n",
    "    if os.path.exists(background_file):\n",
    "        # Load the background audio and adjust its volume\n",
    "        background_audio = AudioSegment.from_file(background_file).apply_gain(volume)\n",
    "        \n",
    "        # Add silence to the beginning of the background audio (one-time delay)\n",
    "        delayed_background = AudioSegment.silent(duration=delay) + background_audio\n",
    "\n",
    "        # Extend the background audio to match the speech audio's length\n",
    "        loops_needed = (len(speech_audio) - len(delayed_background)) // len(background_audio) + 1\n",
    "        extended_background = delayed_background + (background_audio * loops_needed)\n",
    "        \n",
    "        # Trim the background to match the length of the speech audio (no looping)\n",
    "        final_background = extended_background[:len(speech_audio)]\n",
    "\n",
    "        return speech_audio.overlay(final_background), final_background\n",
    "    else:\n",
    "        print(f\"Background file {background_file} not found.\")\n",
    "        return speech_audio, None\n",
    "\n",
    "def generate_ahap(background_file, output_dir=\"ahap_outputs\"):\n",
    "    \"\"\"\n",
    "    Generates an AHAP file from the provided background audio file.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    ahap_output_file = os.path.join(output_dir, os.path.splitext(os.path.basename(background_file))[0] + \".ahap\")\n",
    "    ga.convert_wav_to_ahap(background_file, output_dir, \"sfx\", \"none\")\n",
    "    print(f\"AHAP file saved as '{ahap_output_file}'.\")\n",
    "    return ahap_output_file\n",
    "\n",
    "def process_csv_and_generate_audio_with_ahap(csv_file_path, num_slices=5, section_breaks=5000, background_delay = 5000, output_file=\"final_audio.wav\"):\n",
    "    \"\"\"\n",
    "    Processes a CSV file containing SSML text and sound tags, synthesizes audio,\n",
    "    adds background sounds, generates AHAP files, and combines the results.\n",
    "    \"\"\"\n",
    "    # Load the CSV\n",
    "    data = pd.read_csv(csv_file_path, encoding='latin1')\n",
    "\n",
    "    # Randomly select slices\n",
    "    #selected_slices = data.sample(n=num_slices, random_state=seed)\n",
    "\n",
    "    # Initialize Azure TTS config\n",
    "    speech_config = speechsdk.SpeechConfig(\n",
    "        subscription=os.getenv(\"SPEECH_KEY\"),\n",
    "        region=os.getenv(\"SPEECH_REGION\")\n",
    "    )\n",
    "\n",
    "    # Initialize the combined audio\n",
    "    combined_background = AudioSegment.silent(duration=0)\n",
    "    combined_audio = AudioSegment.silent(duration=0)\n",
    "    audio_break = AudioSegment.silent(duration=section_breaks)\n",
    "\n",
    "    # AHAP generation directory\n",
    "    # ahap_files = []\n",
    "\n",
    "    # Process each slice\n",
    "    for index, row in data.iterrows():\n",
    "        print(\"Index: \", index)\n",
    "        if index > 0:\n",
    "            continue\n",
    "        ssml_text = row['ssml_content']\n",
    "        sound_tag = row['sound_tag']\n",
    "        print(f\"Processing slice with tag '{sound_tag}'...\")\n",
    "\n",
    "        # Synthesize SSML text to audio\n",
    "        speech_audio = synthesize_text_to_audio(ssml_text, speech_config)\n",
    "        if speech_audio is None:\n",
    "            continue \n",
    "\n",
    "        if type(sound_tag) == str:\n",
    "            # Overlay background sound\n",
    "            speech_audio, background_audio = overlay_background_sound(speech_audio, sound_tag, delay = background_delay)\n",
    "        \n",
    "        else:\n",
    "            # If no background sound, use silence for the background\n",
    "            background_audio = AudioSegment.silent(duration=len(speech_audio))\n",
    "\n",
    "        # Add the background audio to the combined background track\n",
    "        combined_background += background_audio\n",
    "        combined_background += audio_break\n",
    "\n",
    "        # Append to combined audio\n",
    "        combined_audio += speech_audio\n",
    "        combined_audio += audio_break\n",
    "        \n",
    "    # Export the merged background audio\n",
    "    merged_background_file = f\"background_{output_file}\"\n",
    "    combined_background.export(merged_background_file, format=\"wav\")\n",
    "\n",
    "    # Export the final combined audio\n",
    "    combined_audio.export(output_file, format=\"wav\")\n",
    "    print(f\"Final audio file saved as '{output_file}'.\")\n",
    "\n",
    "    # Generate a single AHAP file for the merged background\n",
    "    ahap_output_file = f\"ahap_{output_file}\"\n",
    "    generate_ahap(merged_background_file)\n",
    "    print(f\"Merged AHAP file saved as '{ahap_output_file}'.\")\n",
    "\n",
    "    return output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69e81e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  0\n",
      "Processing slice with tag 'grass'...\n",
      "Attributes of audio_config:  {'_AudioOutputStream__handle': <azure.cognitiveservices.speech.interop._Handle object at 0x1308ce590>}\n",
      "SynthesizingAudioCompleted\n",
      "Index:  1\n",
      "Index:  2\n",
      "Index:  3\n",
      "Index:  4\n",
      "Final audio file saved as 'final_audio.wav'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing transient events: 100%|███████████| 175/175 [00:01<00:00, 109.45it/s]\n",
      "Processing continuous events: 432it [00:00, 549.99it/s]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AHAP files generated successfully in 10.48 seconds.\n",
      "Generated files:\n",
      " - ahap_outputs/background_final_audio_combined.ahap\n",
      "AHAP file saved as 'ahap_outputs/background_final_audio.ahap'.\n",
      "Merged AHAP file saved as 'ahap_final_audio.wav'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'final_audio.wav'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_csv_and_generate_audio_with_ahap('mvp_script.csv', section_breaks= 0, background_delay= 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ddd4a0-245e-4b70-9b69-6cb0e23c2ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
